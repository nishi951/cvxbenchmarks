{% extends "utils/problem.j2" %}

{% block vars %}
import scipy.sparse as sps

np.random.seed({{ seed }})
m = {{ m }}
n = {{ n }}
density = {{ density }}

mu = np.exp(0.01*np.random.randn(n))-1  # returns
D = np.random.rand(n)/10;               # idiosyncratic risk
F = sps.rand(n,m,density)                # factor model
F.data = np.random.randn(len(F.data))/10
gamma = 1
B = 1

x = cp.Variable(n)
{% endblock %}

{% block problem %}
f = mu.T*x - gamma*(cp.sum_squares(F.T.dot(x)) +
                    cp.sum_squares(cp.mul_elemwise(D, x)))
C = [cp.sum_entries(x) == B,
     x >= 0]

prob = cp.Problem(cp.Maximize(f), C)
{% endblock %}