{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infinite Push\n",
    "\n",
    "Given a dataset $X_p = \\{x^{+}_1,...,x^{+}_m\\}$ of data vectors classified as \"relevant\" and $X_n = \\{x^{-}_1,...,x^{-}_n\\}$ of data vectors classified as \"irrelevant\", we would like to come up with a linear ranking function $f(x) = w^Tx$ that maximizes the number of relevant vectors in $X_p$ ranked above the highest ranking irrelevant vector. Another way of saying this is that we would like to minimize the maximum number of relevant vectors ranked below any irrelevant vector. In other words, we would like to minimize the function:\n",
    "\n",
    "\\begin{equation}\n",
    "\\max_{1 \\leq j \\leq n} \\sum_{i = 1}^m \\mathbb{1}[f(x^{+}_i) < f(x^{-}_j)]\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbb{1}$ is the indicator function that is 1 when its argument is true and false otherwise.\n",
    "\n",
    "Since this function is not convex (the indicator function is discontinuous) we replace the indicator function with its hinge loss convex relaxation:\n",
    "\n",
    "\\begin{equation}\n",
    "\\max_{1 \\leq j \\leq n} \\sum_{i = 1}^m \\max(1 - (f(x^{+}_i) - f(x^{-}_j)), 0)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\max_{1 \\leq j \\leq n} \\sum_{i = 1}^m \\max(1 - w^T(x^{+}_i - x^{-}_j), 0)\n",
    "\\end{equation}\n",
    "\n",
    "This is a pointwise maximum of affine functions of $w$ and is therefore convex in $w$.\n",
    "\n",
    "We add an $\\ell_2$ regularization term to form the final problem:\n",
    "\\begin{equation*}\n",
    "  \\begin{aligned}\n",
    "    &\\text{minimize} && \\max_{1 \\leq j \\leq n} \\sum_{i = 1}^m \\max(1 - w^T(x^{+}_i - x^{-}_j), 0) + \\lambda \\|w|_2^2 \\\\\n",
    "  \\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "with variable $w$, regularization parameter $\\lambda$, and constants $x^{+}_i$ for $i = 1,...,m$ and $x^{-}_j$ for $j = 1,...,n$.\n",
    "\n",
    "References: Agarwal, Shivani 2011. \"The infinite push: A new support vector ranking algorithm that directly optimizes accuracy at the absolute top of the list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('status:', 'optimal')\n",
      "('optimal value:', 100.00000000044328)\n",
      "('true optimal value:', None)\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# Variable declarations\n",
    "\n",
    "def infinite_push(theta, Xp, Xn):\n",
    "    m, d = Xp.shape\n",
    "    n = Xn.shape[0]\n",
    "    Z = cp.max_elemwise(\n",
    "        1 - (Xp*theta*np.ones((1,n)) - (Xn*theta*np.ones((1,m))).T), 0)\n",
    "    return cp.max_entries(cp.sum_entries(Z, axis=0))\n",
    "\n",
    "def normalized_data_matrix(m, n, mu):\n",
    "    if mu == 1:\n",
    "        # dense\n",
    "        A = np.random.randn(m, n)\n",
    "        A /= np.sqrt(np.sum(A**2, 0))\n",
    "    else:\n",
    "        # sparse\n",
    "        A = sps.rand(m, n, mu)\n",
    "        A.data = np.random.randn(A.nnz)\n",
    "        N = A.copy()\n",
    "        N.data = N.data**2\n",
    "        A = A*sps.diags([1 / np.sqrt(np.ravel(N.sum(axis=0)))], [0])\n",
    "\n",
    "    return A\n",
    "\n",
    "m = 100\n",
    "n = 200\n",
    "d = 20\n",
    "np.random.seed(0)\n",
    "\n",
    "Xp = normalized_data_matrix(m, d, 1)\n",
    "Xn = normalized_data_matrix(n, d, 1)\n",
    "lam = 1\n",
    "\n",
    "theta = cp.Variable(d)\n",
    "f = infinite_push(theta, Xp, Xn) + lam*cp.sum_squares(theta)\n",
    "\n",
    "\n",
    "# Problem construction\n",
    "prob = None\n",
    "opt_val = None\n",
    "\n",
    "prob = cp.Problem(cp.Minimize(f))\n",
    "\n",
    "\n",
    "# For debugging individual problems:\n",
    "if __name__ == \"__main__\":\n",
    "    prob.solve()\n",
    "    print(\"status:\", prob.status)\n",
    "    print(\"optimal value:\", prob.value)\n",
    "    print(\"true optimal value:\", opt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
